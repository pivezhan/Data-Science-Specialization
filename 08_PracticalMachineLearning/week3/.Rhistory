x[good,][1:6,]
x
View(x)
View(x)
x[good,][1:6,]
View(airquality)
View(airquality)
dir()
y<-data.frames(a=1,b="a")
y<-data.frame(a=1,b="a")
dput(y)
dput(y,file="y.R")
new.y=dget("y.R")
new.y
y<-"foo"
x<-data.frame(a=1,b="a")
dump(c("x","y"),file="data.R")
rm(x,y)
source("data.R")
x
y
x<-factor(c("yes","no","yes","no","no"))
x
table(x)
unclass(x)
y
}
y
y
y[1]
clear
y
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
}
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
}
a++
clear
a=0
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a++
}
a=0
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a<-a+1
}
x<-c("a","b","c","d","e")
fori=1:5{
print(x[i])
}
a=0
for i=1 in 10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a<-a+1
}
x<-c("a","b","c","d","e")
fori=1 in 5{
print(x[i])
}
a=0
for i in 1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a<-a+1
}
x<-c("a","b","c","d","e")
fori in 1:5{
print(x[i])
}
x<-c("a","b","c","d","e")
for i in 1:5{
print(x[i])
}
x<-c("a","b","c","d","e")
for (i in 1:5){
print(x[i])
}
a=0
for (i in 1:10){
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
print(y[i])
a<-a+1
}
x<-matrix(1:6,2,3)
for (i in seq_len(nrow(x)))
for (j in seq_len(ncol(x)))
print(x[i,j])
end
end
x<-matrix(1:6,2,3)
for (i in seq_len(nrow(x))){
for (j in seq_len(ncol(x))){
print(x[i,j])
}
}
x
x<-rbinom(1,1.4,.5)
x<-rbinom(1,1.4,0.5)
rbinom
z<-3
while(z<=5 && z>=2){
print(z)
if coin = rbinom(1,1,.5){
z<-z+1
}else{
z<-z-1
}
}
z<-3
while(z<=5 && z>=2){
print(z)
coin = rbinom(1,1,.5)
if coin==1{
z<-z+1
}else{
z<-z-1
}
}
z<-3
while(z<=5 && z>=2){
print(z)
coin = rbinom(1,1,.5)
if (coin==1){
z<-z+1
}else{
z<-z-1
}
}
add2(1,2)
add2(1,2)
add2(1,2)
add2 <- function(x,y){
x+y
}
add2(2)
add2(2,1)
source('C:/Users/lenovo/Desktop/add2.R')
source('C:/Users/lenovo/Desktop/add2.R')
add2(1,2)
source('~/.active-rstudio-document')
x=c(10,20,3,9)
above(x,4)
above(x,10)
source('~/.active-rstudio-document')
columnmean(airquality)
columnmean(airquality)
columnmean(airquality)
source('C:/Users/lenovo/Desktop/add2.R')
columnmean(airquality)
source('C:/Users/lenovo/Desktop/add2.R')
columnmean(airquality)
mydata
mydata=rnorm(100)
source('~/.active-rstudio-document')
f(2,3)
args(paste)
args(cat)
?rnorm
a<-available.packages()
install.packages(KernSmooth)
install.packages("KernSmooth")
library(KernSmooth)
git commit
library(knitr)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("C:/Users/lenovo/Desktop/pack/knitr_1.9.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitrBootstrap_0.9.0.zip", repos = NULL)
rm(lis=ls)
rm(list=ls)
rm(list=ls())
install.packages("C:/Users/lenovo/Desktop/pack/markdown_0.7.4.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitr_1.9.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitrBootstrap_0.9.0.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/rmarkdown_0.5.1.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/roxygen2_4.1.1.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/devtools_1.7.0.zip", repos = NULL)
library(UsingR)
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
setwd("C:\\Users\\lenovo\\Desktop\\Rlearning\\practical machine learning\\week3")
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache=TRUE, cache.path = '.cache/', fig.path = 'fig/')
options(xtable.type = 'html')
par(mar=c(0,0,0,0)); set.seed(1234); x = rep(1:4,each=4); y = rep(1:4,4)
plot(x,y,xaxt="n",yaxt="n",cex=3,col=c(rep("blue",15),rep("red",1)),pch=19)
par(mar=c(0,0,0,0)); set.seed(1234); x = rep(1:4,each=4); y = rep(1:4,4)
plot(x,y,xaxt="n",yaxt="n",cex=3,col=c(rep("blue",15),rep("red",1)),pch=19)
par(mar=c(0,0,0,0));
plot(x,y,xaxt="n",yaxt="n",cex=3,col=c(rep("blue",8),rep("red",8)),pch=19)
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
training <- iris[inTrain,]
data(iris); library(ggplot2);library(caret)
data(iris); library(ggplot2);library(caret);
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
library(caret)
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rattle)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
Species
iris$Species
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
ll <- matrix(NA,nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA,nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
plot(ozone$ozone,temperature,col='lightgrey',pch=19)
points(ozone$ozone,predict(treebag$fits[[1]]$fit,predictors),pch=19,col="red")
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
treebag <- bag(predictors, temperature, B = 10,bagControl = bagControl(fit = ctreeBag$fit,predict = ctreeBag$pred,aggregate = ctreeBag$aggregate))
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
library(caret)
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
temperature = ozone$temperature
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
plot(ozone$ozone,temperature,col='lightgrey',pch=19)
points(ozone$ozone,predict(treebag$fits[[1]]$fit,predictors),pch=19,col="red")
knit_hooks$set(inline = function(x) {
if(is.numeric(x)) {
round(x, getOption('digits'))
} else {
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
plot(ozone$ozone,temperature,col='lightgrey',pch=19)
points(ozone$ozone,predict(treebag$fits[[1]]$fit,predictors),pch=19,col="red")
points(ozone$ozone,predict(treebag,predictors),pch=19,col="blue")
treebag <- bag(predictors, temperature, B = 10,
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
plot(ozone$ozone,temperature,col='lightgrey',pch=19)
points(ozone$ozone,predict(treebag$fits[[1]]$fit,predictors),pch=19,col="red")
points(ozone$ozone,predict(treebag,predictors),pch=19,col="blue")
ctreeBag$fit
ctreeBag$pred
ctreeBag$aggregate
#######random forests
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', cache=TRUE, dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')
options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
if(is.numeric(x)) {
round(x, getOption('digits'))
} else {
paste(as.character(x), collapse = ', ')
}
})
knit_hooks$set(plot = knitr:::hook_plot_html)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
getTree(modFit$finalModel,k=2)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
pred <- predict(modFit,testing); testing$predRight <- pred==testing$Species
#######model based prediction
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
modlda = train(Species ~ .,data=training,method="lda")
modnb = train(Species ~ ., data=training,method="nb")
plda = predict(modlda,testing); pnb = predict(modnb,testing)
table(plda,pnb)
equalPredictions = (plda==pnb)
qplot(Petal.Width,Sepal.Width,colour=equalPredictions,data=testing)
class(1)
class( TRUE )
class(rnorm(100 ))
class( NA)
class(NA)
class( "foo" )
x <- rnorm( 100 )
x <- rnorm( 100 )
y <- x + rnorm( 100 )
fit <- lm(y ~ x)  ## linear regression model
class(fit)
mean
print
methods("mean" )
show
showMethods("show" )
set.seed(10)
x <- rnorm(100)
plot(x)
set.seed(10)
x <- rnorm(100)
x <- as.ts(x)  ## Convert to a time series object
plot(x)
set.seed(10)
x <- rnorm(100)
x <- as.ts(x)  ## Convert to a time series object
plot(x)
set.seed(10)
x <- rnorm(100)
x <- as.ts(x)  ## Convert to a time series object
plot(x)
library (methods)
setClass("polygon" ,
representation(x="numeric" ,
y="numeric"))
setMethod ("plot", "polygon",
function (x, y,  ...) {
plot(x@x, x@y, type =  "n" ,  ...)
xp <- c(x@x, x@x[ 1])
yp <- c(x@y, x@y[ 1])
lines(xp, yp)
})
library (methods)
showMethods("plot")
p <- new( "polygon" , x = c( 1,  2, 3,  4), y = c( 1, 2,  3,  1))
plot(p)
############# R packages ##########
export("mvtsplot")
importFrom(graphics,  "Axis")
import(splines)
export("read.polyfile" , "write.polyfile" )
importFrom(graphics, plot)
exportClasses( "gpc.poly", "gpc.poly.nohole" )
exportMethods( "show", "get.bbox", "plot", "intersect”, " union”, "setdiff",
"[", "append.poly" , "scale.poly", "area.poly", "get.pts",
"coerce", "tristrip", "triangulate" )
\name{line}
\alias{line}
\alias{residuals.tukeyline }
\title{Robust Line Fitting }
\description{
Fit a line robustly as recommended in  \emph{Exploratory Data Analysis }.
}
\usage{
line(x, y)
}
\usage{
Fit a line robustly as recommended in  \emph{Exploratory Data Analysis }.
\alias{residuals.tukeyline }
\title{Robust Line Fitting }
\description{
Fit a line robustly as recommended in  \emph{Exploratory Data Analysis }.
}
\usage{
line(x, y)
}
line(x, y)
}
\arguments{
\item{x, y}{the arguments can be any way of specifying x-y pairs. See
\code{\link{xy.coords}}.}
}
\details{
Cases with missing values are omitted.
Long vectors are not supported.
}
\value{
An object of class\code{"tukeyline"}.
Methods are available for the generic functions\code{coef},
\code{residuals}, \code{fitted}, and\code{print}.
}
\references{
Tukey, J. W. (1977).
\emph{Exploratory Data Analysis },
Reading Massachusetts: Addison-Wesley.
}
system("R CMD build newpackage" )
system("R CMD check newpackage" )
###########
class(1)
class( TRUE )
class(rnorm(100 ))
system("R CMD build newpackage" )
system("R CMD check newpackage" )
\emph{Exploratory Data Analysis },
Reading Massachusetts: Addison-Wesley.
