install.packages("C:/Users/lenovo/Desktop/pack/markdown_0.7.4.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitr_1.9.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitrBootstrap_0.9.0.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/rmarkdown_0.5.1.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/roxygen2_4.1.1.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/devtools_1.7.0.zip", repos = NULL)
library(UsingR)
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
setwd("C:\\Users\\lenovo\\Desktop\\Rlearning\\practical machine learning\\week3")
setwd("C:\\Users\\lenovo\\Desktop\\Rlearning\\practical machine learning\\week4")
library(caret)
library(AppliedPredictiveModeling)
library(ISLR); library(ggplot2);
library(caret);library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
mod1 <- train(y ~.,method="gbm",data=vowel.train);
mod2 <- train(y ~.,method="rf",
data=vowel.train,
trControl = trainControl(method="cv"),number=3)
pred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)
predDF <- data.frame(pred1,pred2,y=vowel.test$y)
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix(as.numeric(vowel.test$y),pred1)
confusionMatrix(as.numeric(vowel.test$y),round(pred2))
identical(levels(pred1),levels(vowel.test$y))
table(pred1,vowel.test$y)
table(vowel.test$y)
round(0.0257986236339071)
head(vowel.test$y)
vowel.test$y
vowel.train$y<-as.factor(vowel.train$y)
table(pred1,vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
library(ISLR); library(ggplot2);
library(caret);library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
mod1 <- train(y ~.,method="gbm",data=vowel.train);
mod2 <- train(y ~.,method="rf",
data=vowel.train,
trControl = trainControl(method="cv"),number=3)
pred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)
predDF <- data.frame(pred1,pred2,y=vowel.test$y)
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
table(pred1,vowel.test$y)
data(vowel.train)
data(vowel.test)
vowel.train$y
table(pred1,vowel.test$y)
data(vowel.train)
table(pred1,vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
table(pred1,vowel.test$y)
pred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)
predDF <- data.frame(pred1,pred2,y=vowel.test$y)
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
table(pred1,vowel.test$y)
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
# Create a building data set and validation set
inBuild <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
validation <- Wage[-inBuild,]; buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y=buildData$wage,
p=0.7, list=FALSE)
training <- buildData[inTrain,]; testing <- buildData[-inTrain,]
dim(training)
dim(testing)
dim(validation)
mod1 <- train(wage ~.,method="glm",data=training)
mod2 <- train(wage ~.,method="rf",
mod1 <- train(wage ~.,method="glm",data=training)
mod1 <- train(wage ~.,method="glm",data=training)
mod2 <- train(wage ~.,method="rf",
data=training,
trControl = trainControl(method="cv"),number=3)
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
predDF <- data.frame(pred1,pred2,wage=testing$wage)
combModFit <- train(wage ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix (testing$wage,pred1)
confusionMatrix(as.numeric(vowel.test$y),pred1)$overall
identical(levels(pred1),levels(vowel.test$y))
# Question 1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
table(vowel.train$y)
set.seed(33833)
require(caret)
M1 <- train(y ~ ., data=vowel.train, method="rf")
M2 <- train(y ~ ., data=vowel.train, method="gbm")
hat1 <- predict(M1, vowel.test)
hat2 <- predict(M2, vowel.test)
confusionMatrix(hat1, vowel.test$y)$overall
confusionMatrix(hat2, vowel.test$y)$overalls
table(hat1,vowel.train$y)
table(hat1,vowel.train$y)
table(hat1,vowel.test$y)
library(caret)
# question1
library(ISLR); library(ggplot2);
library(caret);library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
training<-as.factor(vowel.train$y)
testing<-as.factor(vowel.test$y)
mod1 <- train(y ~.,method="gbm",data=training)
training<-data(vowel.train)
testing<-data(vowel.test)
set.seed(33833)
training$y<-as.factor(vowel.train$y)
testing$y<-as.factor(vowel.test$y)
training$y<-as.factor(training$y)
training$y<-as.factor(training$y)
testing$y<-as.factor(testing$y)
training<-data(vowel.train)
testing<-data(vowel.test)
set.seed(33833)
training$y<-as.factor(training$y)
testing$y<-as.factor(testing$y)
mod1 <- train(y ~.,method="gbm",data=training)
mod1 <- train(y ~.,method="gbm",data=training);
mod1 <- train(y ~.,method="gbm",data=training)
mod2 <- train(y ~.,method="rf", data=training)
training$y<-as.factor(training$y)
testing$y<-as.factor(testing$y)
library(ISLR); library(ggplot2);
library(caret);library(ElemStatLearn)
training<-data(vowel.train)
testing<-data(vowel.test)
set.seed(33833)
training$y<-as.factor(training$y)
library(ISLR); library(ggplot2);
library(caret);library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(testing$y)
vowel.test$y<-as.factor(vowel.test$y)
mod1 <- train(y ~.,method="gbm",data=training)
mod1 <- train(y ~.,method="gbm",data=vowel.train)
mod2 <- train(y ~.,method="rf", data=vowel.train)
pred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)
predDF <- data.frame(pred1,pred2,y=vowel.test)
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
table(pred1,vowel.test$y)
confusionMatrix(as.numeric(vowel.test$y),pred1)$overall
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
pred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)
predDF <- data.frame(pred1,pred2,y=vowel.test)
combModFit <- train(y ~.,method="gam",data=predDF)
predDF <- data.frame(pred1,pred2,y=vowel.test$y)
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
table(pred1,vowel.test$y)
identical(levels(pred1),levels(vowel.test$y))
head(vowel.test$y)
table(pred1,vowel.test$y)
confusionMatrix(as.numeric(vowel.test$y),pred1)$overall
confusionMatrix(as.numeric(vowel.test$y),pred1)$overall
confusionMatrix(as.numeric(vowel.test$y),round(pred2))$overall
confusionMatrix(as.numeric(vowel.test$y),round(combPred))$overall
confusionMatrix(as.numeric(vowel.test$y),pred2)$overall
confusionMatrix(as.numeric(vowel.test$y),combPred)$overall
confusionMatrix(as.numeric(vowel.test$y),pred1)$overall
confusionMatrix(as.numeric(vowel.test$y),pred2)$overall
confusionMatrix(as.numeric(vowel.test$y),combPred)$overall
predDF <- data.frame(pred1,pred2,y=vowel.test$y,agree = hat1 == hat2)
accuracy <- sum(pred1[predDF$agree] == predDF$y[predDF$agree]) / sum(predDF$agree)
accuracy
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
table(vowel.train$y)
set.seed(33833)
require(caret)
M1 <- train(y ~ ., data=vowel.train, method="rf")
M2 <- train(y ~ ., data=vowel.train, method="gbm")
hat1 <- predict(M1, vowel.test)
hat2 <- predict(M2, vowel.test)
confusionMatrix(hat1, vowel.test$y)$overall
confusionMatrix(hat2, vowel.test$y)$overall
hat <- data.frame(hat1,
hat2,
y = vowel.test$y,
agree = hat1 == hat2)
accuracy <- sum(hat1[hat$agree] == hat$y[hat$agree]) / sum(hat$agree)
accuracy
library(caret);library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
mod1 <- train(y ~.,method="gbm",data=vowel.train)
mod2 <- train(y ~.,method="rf", data=vowel.train)
pred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)
predDF <- data.frame(pred1,pred2,y=vowel.test$y,agree = hat1 == hat2)
accuracy <- sum(pred1[predDF$agree] == predDF$y[predDF$agree]) / sum(predDF$agree)
accuracy
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix(as.numeric(vowel.test$y),pred1)$overall
confusionMatrix(as.numeric(vowel.test$y),pred2)$overall
confusionMatrix(as.numeric(vowel.test$y),combPred)$overall
# Question 2
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(adData)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
head(adData)
predictors
head(predictors)
head(AlzheimerDisease)
head(AlzheimerDisease$predictors)
head(training)
library(caret)
library(gbm)
set.seed(3433)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
adData = data.frame(diagnosis,predictors)
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1 <- train(diagnosis ~.,method="gbm",data=training)
mod2 <- train(diagnosis ~.,method="rf", data=training)
mod3 <- train(diagnosis ~.,method="lda",data=training)
library(gbm);library(MASS)
mod3 <- train(diagnosis ~.,method="lda",data=training)
library(caret)
library(gbm);library(MASS)
library(AppliedPredictiveModeling)
mod3 <- train(diagnosis ~.,method="lda",data=training)
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
pred3 <- predict(mod3,testing);
predDF <- data.frame(pred1,pred2,pred3,y=vowel.test$y)
mod3
predDF <- data.frame(pred1,pred2,pred3,y=vowel.test$y)
library(caret)
library(mlbench)
mod3 <- train(diagnosis ~.,method="lda",data=training)
require 'rubygems'
require 'lda-ruby'
require ('rubygems')
require (rubygems)
require (lda-ruby)
require (rubygems)
mod1 <- train(diagnosis ~.,method="gbm",data=training)
library(caret)
library(gbm);library(MASS)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1 <- train(diagnosis ~.,method="gbm",data=training)
mod2 <- lda(diagnosis ~. , data=training )
mod2 <- lda(diagnosis ~. , data=training )
mod3 <- train(diagnosis ~.,method="lda",data=training)
mod3 <- train(diagnosis ~.,method="rf",data=training)
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
pred3 <- predict(mod3,testing);
predDF <- data.frame(pred1,pred2,pred3,y=vowel.test$y)
predDF <- data.frame(pred1,pred2,pred3,y=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
combPred <- predict(combModFit,predDF)
combModFit <- train(diagnosis ~.,method="gam",data=predDF)
combModFit <- train(diagnosis ~.,method="gam",data=predDF)
length(pred1)
length(red2)
length(pred2)
pred2 <- predict(mod2,testing);
mod2
nrow(mod2)
head(mod2)
length(mod2)
length(mod1)
length(mod3)
mod2 <- train(diagnosis ~.,method="lda" , data=training )
length(mod2)
pred1 <- predict(mod1,testing);
pred2 <- predict(mod2,testing);
pred3 <- predict(mod3,testing);
predDF <- data.frame(pred1,pred2,pred3,y=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="gam",data=predDF)
length(pred1)
length(pred2)
length(pred3)
ncol(pred3)
str(pred3)
str(pred1)
str(pred2)
predDF <- data.frame(pred1,pred2,pred3,y=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
str(pred2)
str(pred1)
str(pred3)
length(pred3)
length(pred1)
length(pred2)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
combPred <- predict(combModFit,predDF)
length(pred1)
length(pred2)
predDF <- data.frame(pred1,pred2,pred3,y=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
table(pred1,pred2,pred3)
table(pred1,pred2)
table(pred1,diagnosis)
table(pred1,testing$diagnosis)
table(pred1,testing$diagnosis)
table(pred2,testing$diagnosis)
table(pred3,testing$diagnosis)
str(predDF)
predDF <- data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix(as.numeric(testing$diagnosis),pred1)$overall
confusionMatrix(as.numeric(testing$diagnosis),pred2)$overall
confusionMatrix(as.numeric(testing$diagnosis),pred3)$overall
confusionMatrix(as.numeric(testing$diagnosis),combPred)$overall
confusionMatrix(testing$diagnosis,pred1)$overall
confusionMatrix(testing$diagnosis,pred2)$overall
confusionMatrix(testing$diagnosis,pred3)$overall
confusionMatrix(testing$diagnosis,combPred)$overall
?plot.enet
?plot.enet
??plot.enet
M1 <- train(CompressiveStrength ~ ., data=training, method="lasso")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
??plot.enet
set.seed(233)
set.seed(233)
M1 <- train(CompressiveStrength ~ ., data=training, method="lasso")
M1
plot(M1$finalModel, xvar="penalty")
library(lubridate)  # For year() function below
dat = read.csv("~/gaData.csv")
library(lubridate)  # For year() function below
dat = read.csv("~/gaData.csv")
setwd("C:\\Users\\lenovo\\Desktop\\Rlearning\\practical machine learning\\week4")
dat = read.csv("~/gaData.csv")
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats()
library(lubridate)  # For year() function below
library(forecast)
library(forecast)
?bats
fit <- bats(training, use.parallel=FALSE)
fit <- bats(tstrain, use.parallel=FALSE)
plot(forecast(fit))
plot(forecast(fit))
prediction         <- predict(fit,testing$visitsTumblr)
prediction<- predict(fit,testing$visitsTumblr)
tstest <- ts(testing$visitsTumblr)
prediction<- predict(fit,tstest)
prediction<- predict(fit,tstest)
tstrain = ts(training$visitsTumblr)
tstest <- ts(testing$visitsTumblr)
plot(forecast(fit));lines(ts1Test,col="red")
plot(forecast(fit));lines(ts1Test,col="red")
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest <- ts(testing$visitsTumblr)
fit <- bats(tstrain, use.parallel=FALSE)
plot(forecast(fit));lines(ts1Test,col="red")
plot(forecast(fit));
lines(ts1Test,col="red")
lines(tsTest,col="red")
lines(tstest,col="red")
accuracy(fcast,ts1Test)
accuracy(fcast,tstest)
accuracy(fit,tstest)
fcast <- forecast(fit)
accuracy(fcast,tstest)
accuracy(fcast,tstest)
fcast <- forecast(fit)
lines(tstest,col="red")
accuracy(fcast,tstest)
fcast
tstest
##question 5
library(AppliedPredictiveModeling);library(e1071)
library(AppliedPredictiveModeling);library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
x <- subset(iris, select = -Species)
y <- Species
model <- svm(concrete, concrete$CompressiveStrength)
summary(model)
model <- svm(concrete$CompressiveStrength.~)
model <- svm(concrete$CompressiveStrength~.)
head(concrete)
model <- svm(concrete$CompressiveStrength,data=training)
print(model)
summary(model)
pred <- predict(model, testing$CompressiveStrength)
pred <- predict(model, testing$CompressiveStrength)
pred <- predict(model, testing$CompressiveStrength)
sqrt(sum((pred-testing$CompressiveStrength)^2))
model <- svm(concrete$CompressiveStrength,data=training)
pred <- predict(model, training$CompressiveStrength)
sqrt(sum((pred-testing$CompressiveStrength)^2))
sqrt(sum((pred-testing$CompressiveStrength)^2))
pred <- predict(model, testing)
pred <- predict(model, testing)
library(AppliedPredictiveModeling);library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model <- svm(concrete$CompressiveStrength,data=training)
pred <- predict(model, testing)
pred <- predict(model,testing)
sqrt(sum((pred-testing$CompressiveStrength)^2))
pred1 <- predict(model,testing)
testing
pred <- predict(model,testing)
pred <- predict(model,testing$CompressiveStrength)
sqrt(sum((pred-testing$CompressiveStrength)^2))
testing
sqrt(sum((pred-testing$CompressiveStrength)^2))
model <- svm(CompressiveStrength,data=training)
model <- svm(CompressiveStrength,data=training)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model <- svm(CompressiveStrength,data=training)
names(training)
model <- svm(CompressiveStrength.~,data=training)
model <- svm(CompressiveStrength~.,data=training)
pred <- predict(model,testing$CompressiveStrength)
pred <- predict(model,testing)
sqrt(sum((pred-testing$CompressiveStrength)^2))
sqrt(sum((pred-testing$CompressiveStrength)^2))/length(testing$CompressiveStrength)
length(testing$CompressiveStrength)
testing$CompressiveStrength
pred
length(pred)
sqrt(sum((pred-testing$CompressiveStrength)^2)/length(testing$CompressiveStrength))
fit <- bats(tstrain)
fcast <- forecast(fit,length(testing$visitsTumblr))
library(lubridate)  # For year() function below
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(testing$visitsTumblr)
fit <- bats(tstrain)
plot(forecast(fit));
fcast <- forecast(fit,length(testing$visitsTumblr))
hat <- cbind(testing, data.frame(fcast))
hat$isIn95 <- hat$Lo.95 < hat$visitsTumblr & hat$visitsTumblr < hat$Hi.95
prop.table(table(hat$isIn95))
fit
prop.table(table(hat$isIn95))
