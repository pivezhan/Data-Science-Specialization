plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
q()
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
X <- 0.71*training$num415 + 0.71*training$num857
Y <- 0.71*training$num415 - 0.71*training$num857
plot(X,Y)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
q()
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
confusionMatrix(testing$type,predict(modelFit,testPC))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
cutWage <- cut2(training$wage,g=3)
table(cutWage)
qplot(CompressiveStrength,colour=education,data=training,geom="density")
qplot(CompressiveStrength,colour=training ,data=training,geom="density")
qplot(CompressiveStrength ,data=training,geom="density")
q()
qplot(CompressiveStrength,colour=training ,data=training,geom="density")
data(concrete)
training = mixtures[ inTrain,]
data(concrete)
data(1 2)
a=(1)
a=(1,2)
a=(1;2)
a=(1,2)
a=(1;2)
a=(1,2)
a=(1;2)
a=(1;2)
a=[1,2]
a=[1;2]
data(concrete)
training = mixtures[ inTrain,]
qplot(CompressiveStrength,colour=training ,data=training,geom="density")
inTrain <- createDataPartition(y=Wage$wage,
q()
q()
q
.Internal(quit(save, status, runLast))
quit(save, status, runLast)
quit(save)
yes
quit(save,yes)
help quit
q()
View(andy)
dir()
getwd()
dir()
getwd()
cd c:/Users/lenovo/desktop
cd (c:/Users/lenovo/desktop)
getwd()
dir()
getwd()
setwd("~/")
getwd(C:/Users/lenovo)
setwd("~/")
getwd(C:/Users/lenovo)
setwd("~/C:\Users\lenovo\Desktop\Rlearning")
setwd("C:\Users\lenovo\Desktop\Rlearning")
setwd("~/")
getwd(C:/Users/lenovo)
getwd(C:/Users/lenovo)
getwd()
setwd("~/")
C:\Users\lenovo\Desktop\Rlearning
x<-list(foo=1:4,bar=0.6)
x$bar
save.image("C:/Users/lenovo/Desktop/a.RData")
x$foo
x[[1]][[3]]
x[[1]][[4]]
x[[2]][[1]]
x[[2]][[1]]
airquality(1:6,)
airquality[1:6,]
x<-airquality[1:6,]
View(x)
View(x)
View(x)
good=complete.cases(x)
x[good,][1:6,]
good
x
airquality[good,][1:6,]
x[good,][1:6,]
x
View(x)
View(x)
x[good,][1:6,]
View(airquality)
View(airquality)
dir()
y<-data.frames(a=1,b="a")
y<-data.frame(a=1,b="a")
dput(y)
dput(y,file="y.R")
new.y=dget("y.R")
new.y
y<-"foo"
x<-data.frame(a=1,b="a")
dump(c("x","y"),file="data.R")
rm(x,y)
source("data.R")
x
y
x<-factor(c("yes","no","yes","no","no"))
x
table(x)
unclass(x)
y
}
y
y
y[1]
clear
y
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
}
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
}
a++
clear
a=0
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a++
}
a=0
for i=1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a<-a+1
}
x<-c("a","b","c","d","e")
fori=1:5{
print(x[i])
}
a=0
for i=1 in 10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a<-a+1
}
x<-c("a","b","c","d","e")
fori=1 in 5{
print(x[i])
}
a=0
for i in 1:10{
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
a<-a+1
}
x<-c("a","b","c","d","e")
fori in 1:5{
print(x[i])
}
x<-c("a","b","c","d","e")
for i in 1:5{
print(x[i])
}
x<-c("a","b","c","d","e")
for (i in 1:5){
print(x[i])
}
a=0
for (i in 1:10){
if (a<3){
y[i]<-1
}else{
y[i]<-0
}
print(y[i])
a<-a+1
}
x<-matrix(1:6,2,3)
for (i in seq_len(nrow(x)))
for (j in seq_len(ncol(x)))
print(x[i,j])
end
end
x<-matrix(1:6,2,3)
for (i in seq_len(nrow(x))){
for (j in seq_len(ncol(x))){
print(x[i,j])
}
}
x
x<-rbinom(1,1.4,.5)
x<-rbinom(1,1.4,0.5)
rbinom
z<-3
while(z<=5 && z>=2){
print(z)
if coin = rbinom(1,1,.5){
z<-z+1
}else{
z<-z-1
}
}
z<-3
while(z<=5 && z>=2){
print(z)
coin = rbinom(1,1,.5)
if coin==1{
z<-z+1
}else{
z<-z-1
}
}
z<-3
while(z<=5 && z>=2){
print(z)
coin = rbinom(1,1,.5)
if (coin==1){
z<-z+1
}else{
z<-z-1
}
}
add2(1,2)
add2(1,2)
add2(1,2)
add2 <- function(x,y){
x+y
}
add2(2)
add2(2,1)
source('C:/Users/lenovo/Desktop/add2.R')
source('C:/Users/lenovo/Desktop/add2.R')
add2(1,2)
source('~/.active-rstudio-document')
x=c(10,20,3,9)
above(x,4)
above(x,10)
source('~/.active-rstudio-document')
columnmean(airquality)
columnmean(airquality)
columnmean(airquality)
source('C:/Users/lenovo/Desktop/add2.R')
columnmean(airquality)
source('C:/Users/lenovo/Desktop/add2.R')
columnmean(airquality)
mydata
mydata=rnorm(100)
source('~/.active-rstudio-document')
f(2,3)
args(paste)
args(cat)
?rnorm
a<-available.packages()
install.packages(KernSmooth)
install.packages("KernSmooth")
library(KernSmooth)
git commit
library(knitr)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("C:/Users/lenovo/Desktop/pack/knitr_1.9.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitrBootstrap_0.9.0.zip", repos = NULL)
rm(lis=ls)
rm(list=ls)
rm(list=ls())
install.packages("C:/Users/lenovo/Desktop/pack/markdown_0.7.4.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitr_1.9.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/knitrBootstrap_0.9.0.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/rmarkdown_0.5.1.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/roxygen2_4.1.1.zip", repos = NULL)
install.packages("C:/Users/lenovo/Desktop/pack/devtools_1.7.0.zip", repos = NULL)
library(UsingR)
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
setwd("C:\\Users\\lenovo\\Desktop\\Rlearning\\r programming\\week3")
s <- split(iris, iris$Species)
sapply(s, function(x) colMeans(x[, c("Sepal.Length")],na.rm = TRUE))
s <- split(iris, iris$Species)
sapply(s, function(x) colMeans(x[, c("Sepal.Length","Sepal.Width", "Petal.Length ")],na.rm = TRUE))
names(iris)
names(airquality)
# data(iris)
s <- split(airquality, airquality$Wind)
sapply(s, function(x) colMeans(x[, c("Month","Day",
"Solar.R")],na.rm = TRUE))
names(iris)
s <- split(Species,iris$Species)
s <- split(iris,iris$Species)
sapply(s, function(x) colMeans(x[, c("Sepal.Width","Petal.Width",
"Petal.Length")],na.rm = TRUE))
?mtcars
sapply(split(mtcars$mpg, mtcars$cyl), mean)
x<-sapply(split(mtcars$mpg, mtcars$cyl), mean)
x[2,1]
x[1]
x[1,2]
x[1,1]
dim(x)
x
x[3]
x[1]-x[3]
debug(ls)
ls
debug(lm)
lm(y ~ x)
s <- split(iris,iris$Species)
sapply(s, function(x) colMeans(x[, c("Sepal.Width","Petal.Width",
"Petal.Length")],na.rm = TRUE))
sapply(s, function(x) colMeans(x[, c("Sepal.length","Petal.Width",
"Petal.Length")],na.rm = TRUE))
iris
names(iris)
sapply(s, function(x) colMeans(x[, c("Sepal.Length","Petal.Width",
"Petal.Length")],na.rm = TRUE))
sapply(split(mtcars$mpg, mtcars$cyl), mean)     Correct 	1
sapply(split(mtcars$mpg, mtcars$cyl), mean)
debug(ls)
ls
ls()
g
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
names(mtcars)
tapply(mtcars$hp, mtcars$cyl, mean)
h<-tapply(mtcars$hp, mtcars$cyl, mean)
h[3]-h[1]
set.seed(13435)
X <- data.frame( "var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample( 1:5),]; X$var2[c( 1,3)] = NA
setwd(C:\Users\lenovo\Desktop\Rlearning\Getting and Cleaning Data\week3)
setwd("C:\Users\lenovo\Desktop\Rlearning\Getting and Cleaning Data\week3")
setwd("C:/Users/lenovo/Desktop/Rlearning/Getting and Cleaning Data/week3")
X <- X[sample( 1:5),]; X$var2[c( 1,3)] = NA
X
sample(1:5)
sample(1:6)
x[,1]
X <- data.frame( "var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample( 1:5),]; X$var2[c( 1,3)] = NA
X
# subsetting
x[,1]
X[,1]
X[,"var1"]
X[1:2,"var2"]
X[(X$var1 <= 3& X$var3 > 11),]
X
# subsetting
X[,1]
X[1:2,"var2"]
X[(X$var1 <= 3& X$var3 > 11),]
X[(X$var1 <= 3| X$var3 > 15),]
sort(X$var1)
sort(X$var1,decreasing= TRUE)
sort(X$var2,na.last= TRUE)
X[order(X$var1),]
X[order(X$var1,X$var3),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm( 5)
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists( "./data")){dir.create( "./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile= "./data/restaurants.csv" ,method="curl")
restData <- read.csv( "./data/restaurants.csv" )
if(!file.exists( "./data")){dir.create( "./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile= "./data/restaurants.csv" ,method="curl")
download.file(fileUrl,destfile= "./data/restaurants.csv" )
restData <- read.csv( "./data/restaurants.csv" )
head(restData,n= 3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.rm= TRUE)
str(restData)
quantile(restData$councilDistrict,na.rm= TRUE)
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
table(restData$zipCode,useNA= "ifany")
names(restData)
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))== 0)
table(restData$zipCode % in% c("21212"))
table(restData$zipCode %in% c("21212"))
table(restData$zipCode % in% c("21212","21213"))
table(restData$zipCode %in% c("21212","21213"))
restData[restData$zipCode %in% c("21212","21213"),]
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
xt
warpbreaks$replicate <- rep( 1:9, len = 54)
xt = xtabs(breaks ~.,data=warpbreaks)
xt
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
xt
warpbreaks$replicate <- rep( 1:9, len = 54)
xt = xtabs(breaks ~.,data=warpbreaks)
xt
fakeData = rnorm( 1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
fakeData=rnorm(1e5)
object.size(fakeData)
fakeData=rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
if(!file.exists( "./data")){dir.create( "./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile= "./data/restaurants.csv" ,method="curl")
if(!file.exists( "./data")){dir.create( "./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile= "./data/restaurants.csv")
restData <- read.csv( "./data/restaurants.csv" )
s1 <- seq(1,10,by=2) ; s1
s1 <- seq(1,10,by=1) ; s1
s1 <- seq(1,10,by=3) ; s1
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park" , "Homeland")
table(restData$nearMe)
restData$nearMe = restData$neighborhood %in% c("Roland Park" )
table(restData$nearMe)
restData$neighborhood
restData$nearMe
summary(restData)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode < 0)
restData$zipGroups = cut(restData$zipCode,breaks=quantile(restData$zipCode))
table(restData$zipGroups)
table(restData$zipGroups,restData$zipCode)
library(Hmisc)
library(Hmisc)
getwd()
source('C:/Users/lenovo/Desktop/Rlearning/Getting and Cleaning Data/week3/getting2week3.R', echo=TRUE)
library(Hmisc)
