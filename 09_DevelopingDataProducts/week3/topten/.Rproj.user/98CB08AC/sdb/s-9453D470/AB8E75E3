{
    "contents" : "setwd(\"C:\\\\Users\\\\lenovo\\\\Desktop\\\\Rlearning\\\\practical machine learning\\\\week4\")\n\n###regularized regression\nlibrary(ElemStatLearn); data(prostate)\nstr(prostate)\n\nsmall = prostate[1:5,]\nlm(lpsa ~ .,data =small)\n\n####combining predictor\nlibrary(ISLR); data(Wage); library(ggplot2); library(caret);\nWage <- subset(Wage,select=-c(logwage))\n\n# Create a building data set and validation set\ninBuild <- createDataPartition(y=Wage$wage,\n                               p=0.7, list=FALSE)\nvalidation <- Wage[-inBuild,]; buildData <- Wage[inBuild,]\n\ninTrain <- createDataPartition(y=buildData$wage,\n                               p=0.7, list=FALSE)\ntraining <- buildData[inTrain,]; testing <- buildData[-inTrain,]\n\n\ndim(training)\ndim(testing)\ndim(validation)\n\nmod1 <- train(wage ~.,method=\"glm\",data=training)\nmod2 <- train(wage ~.,method=\"rf\",\n              data=training, \n              trControl = trainControl(method=\"cv\"),number=3)\n\npred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)\nqplot(pred1,pred2,colour=wage,data=testing)\n\npredDF <- data.frame(pred1,pred2,wage=testing$wage)\ncombModFit <- train(wage ~.,method=\"gam\",data=predDF)\ncombPred <- predict(combModFit,predDF)\n\nsqrt(sum((pred1-testing$wage)^2))\nsqrt(sum((pred2-testing$wage)^2))\nsqrt(sum((combPred-testing$wage)^2))\n\npred1V <- predict(mod1,validation); pred2V <- predict(mod2,validation)\npredVDF <- data.frame(pred1=pred1V,pred2=pred2V)\ncombPredV <- predict(combModFit,predVDF)\n\nsqrt(sum((pred1V-validation$wage)^2))\nsqrt(sum((pred2V-validation$wage)^2))\nsqrt(sum((combPredV-validation$wage)^2))\n\n####unsupervised learning\ndata(iris); library(ggplot2)\ninTrain <- createDataPartition(y=iris$Species,\n                               p=0.7, list=FALSE)\ntraining <- iris[inTrain,]\ntesting <- iris[-inTrain,]\ndim(training); dim(testing)\n\n#cluster with kmeans\nkMeans1 <- kmeans(subset(training,select=-c(Species)),centers=3)\ntraining$clusters <- as.factor(kMeans1$cluster)\nqplot(Petal.Width,Petal.Length,colour=clusters,data=training)\n\n##compare with real values\ntable(kMeans1$cluster,training$Species)\n\n# build predictor\nmodFit <- train(clusters ~.,data=subset(training,select=-c(Species)),method=\"rpart\")\ntable(predict(modFit,training),training$Species)\n\n\n##apply to test\ntestClusterPred <- predict(modFit,testing) \ntable(testClusterPred ,testing$Species)\n\n#########forecasting\nlibrary(quantmod)\nfrom.dat <- as.Date(\"01/01/08\", format=\"%m/%d/%y\")\nto.dat <- as.Date(\"12/31/13\", format=\"%m/%d/%y\")\ngetSymbols(\"GOOG\", src=\"google\", from = from.dat, to = to.dat)\nhead(GOOG)\n\nmGoog <- to.monthly(GOOG)\ngoogOpen <- Op(mGoog)\nts1 <- ts(googOpen,frequency=12)\nplot(ts1,xlab=\"Years+1\", ylab=\"GOOG\")\n\nplot(decompose(ts1),xlab=\"Years+1\")s\n\nts1Train <- window(ts1,start=1,end=5)\nts1Test <- window(ts1,start=5,end=(7-0.01))\nts1Train\n\nplot(ts1Train)\nlines(ma(ts1Train,order=3),col=\"red\")\n\nets1 <- ets(ts1Train,model=\"MMM\")\nfcast <- forecast(ets1)\nplot(fcast); lines(ts1Test,col=\"red\")\n\naccuracy(fcast,ts1Test)\n\n\n# QUIZ 4\n\n# question1\nlibrary(ISLR); library(ggplot2); \nlibrary(caret);library(ElemStatLearn)\ndata(vowel.train)\ndata(vowel.test) \nset.seed(33833)\nmod1 <- train(y ~.,method=\"gbm\",data=vowel.train);\nmod2 <- train(y ~.,method=\"rf\",\n              data=vowel.train, \n              trControl = trainControl(method=\"cv\"),number=3)\n\npred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)\n\npredDF <- data.frame(pred1,pred2,y=vowel.test$y)\ncombModFit <- train(y ~.,method=\"gam\",data=predDF)\ncombPred <- predict(combModFit,predDF)\n\nconfusionMatrix(as.numeric(vowel.test$y),pred1)\nconfusionMatrix(as.numeric(vowel.test$y),round(pred2))\nconfusionMatrix(as.numeric(vowel.test$y),round(combPred))\n\nlibrary(caret)\nlibrary(AppliedPredictiveModeling)\nset.seed(3433)\ndata(AlzheimerDisease)\nadData = data.frame(diagnosis,predictors)\ninTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]\ntraining = adData[inTrain,]\ntesting = adData[-inTrain,]\nmodFit <- train(diagnosis ~ ., method = \"glm\", data=training)\n# There were 50 or more warnings (use warnings() to see the first 50)\npred <- predict(modFit, testing)\nconfusionMatrix (testing$diagnosis,pred)\nhead(AlzheimerDisease)\nlength(pred)\nlength(testing$diagnosis)\n",
    "created" : 1430682140471.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4259943507",
    "id" : "AB8E75E3",
    "lastKnownWriteTime" : 1430729456,
    "path" : "C:/Users/lenovo/Desktop/Rlearning/practical machine learning/week4/mlearn4.R",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}